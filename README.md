# The purpose of this repository
This repository contains codes for the adversarial attacks and defenses in this paper
# Adversarial Attacks
The adversarial attacks that the paper focuses on are as following:
|Name | Paper|
|----|----|
| FGSM (Linf)| Explaining and harnessing adversarial examples ([Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572)) |
| BIM (Linf)| Adversarial Examples in the Physical World ([Kurakin et al., 2016](https://arxiv.org/abs/1607.02533)) |
| PGD (L2) | Towards Deep Learning Models Resistant to Adversarial Attacks ([Mardry et al., 2017](https://arxiv.org/abs/1706.06083))|
| CW (L2) | Towards Evaluating the Robustness of Neural Networks ([Carlini et al., 2016](https://arxiv.org/abs/1608.04644)) |

We generate attacks from four different image sets: CIFAR10, CIFAR100, MNIST and IMAGENET  
Each set uses 5 different backbone models: Resnet50, Resnet101, MobileNet v2, DenseNet121, AlexNet and InceptionNet v3  
The code used to generate the attacks and their top 1 and top 5 accuracies is `adversarial_attacks_get_results.py`

Usage: We index the datasets and models used as backbone in the code for convenience
* `adversarial_attacks_get_result.py` is used to generate adversarial attacks along side the top 1 and top 5 accuracies of the model on both the original and the adversarial datasets.
* Note:
  - Datasets (alongside a json file of the labels) and Models should be prepared beforehand: Most datasets can be downloaded via pytorch's Dataset, except for IMGNET. Models from pytorch are trained on IMGNET, while the code requires them to be trained on other datasets as well.
  - The code is mostly for reference purpose.
# Adversarial Defense  
There are three training methods that are reviewed in the paper:  
* ATWR: adversarial attacks generated by PGD L2 method are used to train (index number: 0)  
* ATGR: adversarial attacks generated by PGD L2 method are used to train (index number: 1)  
* EATR: adverarial attacks generated by all four methods are used to train (index number: 2)
  
Usage: We also index these training methods for convenience  
* We pre-trained the models using normal datasets before applying the methods on them. The codes used are `ATWR_train.py`, `ATGR_train.py` and `EATR_train.py` respectively  
* The top 1 and top 5 results are taken with `adversarial_defense_get_results.py`  
* Note: The codes are mostly for reference purpose.  




