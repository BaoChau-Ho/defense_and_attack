# The purpose of this repository
This repository contains codes for the adversarial attacks and defenses in this paper: [blank link]()
# Adversarial Attacks
The adversarial attacks that the paper focus on are as following:
|Name | Paper|
|----|----|
| FGSM (Linf)| Explaining and harnessing adversarial examples (Goodfellow et al., 2014) |
| BIM (Linf)| Adversarial Examples in the Physical World (Kurakin et al., 2016) |
| PGD (L2) | Towards Deep Learning Models Resistant to Adversarial Attacks (Mardry et al., 2017)|
| CW (L2) | Towards Evaluating the Robustness of Neural Networks (Carlini et al., 2016) |
