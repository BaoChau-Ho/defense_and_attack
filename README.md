# The purpose of this repository
This repository contains codes for the adversarial attacks and defenses in this paper: [blank link]()
# Adversarial Attacks
The adversarial attacks that the paper focus on are as following:
|Name | Paper|
|----|----|
| FGSM (Linf)| Explaining and harnessing adversarial examples ([Goodfellow et al., 2014](https://arxiv.org/abs/1412.6572)) |
| BIM (Linf)| Adversarial Examples in the Physical World ([Kurakin et al., 2016](https://arxiv.org/abs/1607.02533)) |
| PGD (L2) | Towards Deep Learning Models Resistant to Adversarial Attacks ([Mardry et al., 2017](https://arxiv.org/abs/1706.06083))|
| CW (L2) | Towards Evaluating the Robustness of Neural Networks ([Carlini et al., 2016](https://arxiv.org/abs/1608.04644)) |
